---
j vhcQ!---
title: "projet1"
format: html
editor: visual
---

# l- CLASSIFICATION DES DÉPARTEMENTS PAR PROFIL DE VOTE (CAH)

```{r}
library(readr)
library(dplyr)
```

```{r}
# Charger le jeu de données
data_votes <- read_delim("Presidentielle2017_par_departement.csv", delim = ",")

colonnes_vote <- c("Abstentions", "Blancs", "Arthaud", "Asselineau", "Cheminade",
                   "DupontAignan", "Fillon", "Hamon", "Lasalle", "LePen",
                   "Macron", "Melenchon", "Poutou")
```

# Première question:

La fonction `dist()` de Base R, utilisée sans spécifier la méthode, applique la **Distance Euclidienne** (`method = "euclidean"`). C'est la distance géométrique standard, qui calcule l'écart direct entre les départements dans l'espace des votes.

Ou `"maximum"`, `"manhattan"`, `"canberra"`, `"binary"` or `"minkowski"`.

Les classes **ne peuvent pas** être lues directement sur l'objet `hclust`. Cet objet contient l'arbre. Pour obtenir les classes (c'est-à-dire l'appartenance de chaque département à un groupe), il faut **couper l'arbre** à une hauteur ou un nombre de groupes précis, en utilisant la fonction **`cutree()`** . C'est la question suivante

```{r}

data_cah_brut <- data_votes[, colonnes_vote]

rownames(data_cah_brut) <- data_votes$Dpt # Utiliser le nom du département comme label

# Calcul de la Matrice des Distances
matrice_distances_brut <- dist(data_cah_brut, method = "euclidean")

# Application de la CAH 
# CHOIX DU LIEN : Lien Complet (méthode "complete", par défaut de hclust)
# Le lien complet (farthest neighbor) utilise la distance maximale entre les points de deux clusters pour leur fusion, tendant à former des groupes compacts.

cah_brut <- hclust(matrice_distances_brut, method = "complete")




# Coupure de l'arbre pour k=3 afin d'identifier les plus gros outliers (effet de taille)
k_coupe_brut <- 3
groupes_3_brut <- cutree(cah_brut, k = k_coupe_brut)

print(paste("Répartition des groupes (Votes Bruts, k=", k_coupe_brut, ") :"))
print(table(groupes_3_brut))

# Diagnostic : Le groupe le plus petit correspond aux départements les plus peuplés
# (ou aux agrégats de grande taille comme 'Français établis hors de France'),
# confirmant que la classification est basée sur l'échelle et non le profil.



```

# Deuxième question:

-   **Hauteurs des branches :** Les hauteurs sur l'axe vertical du dendrogramme représentent la **distance Euclidienne** entre les deux groupes ou départements qui ont fusionné à ce niveau. Plus la hauteur est grande, plus les groupes sont différents.

-   **Commentaire sur l'Outlier :** Dans une CAH basée sur les nombres bruts, le résultat est presque toujours dominé par le facteur **échelle (population)**. Le département avec le plus grand nombre de votes (d'inscrits) aura des valeurs très différentes des petits départements. Il apparaîtra comme un **outlier**, ne fusionnant avec le reste qu'à une **très grande hauteur** sur le dendrogramme et c'est 'Français établis hors de France'.

```{r}

# Tracer l'arbre (Dendrogramme)
plot(cah_brut,
     main = "Dendrogramme de la CAH (Votes Bruts - Effet de Taille)",
     xlab = "Départements",
     ylab = "Hauteur (Distance Euclidienne Brute)",
     hang = -1,
     cex=0.4) # 'hang = -1' aligne les labels

#encadrer les groupes
rect.hclust(cah_brut,k=3,border = 2:6)

print(paste("Répartition des groupes (Votes Bruts, k=", k_coupe_brut, ") :"))
print(table(groupes_3_brut))
groupes_3_brut[3]

```

```{r}
# ==============================================================================
# GRAPHIQUE DE VÉRIFICATION DE L'EFFET DE TAILLE (INSCRIITS vs Dpt)
# ==============================================================================

data_plot <- data_votes[, c("Dpt", "Inscrits")]

# Trier les données par nombre d'Inscrits (croissant) pour la lisibilité
data_plot <- data_plot[order(data_plot$Inscrits), ]

# Créer un vecteur de hauteurs pour le graphique à barres
hauteurs <- data_plot$Inscrits / 1000 # Divisé par 1000 pour avoir des milliers d'inscrits sur l'axe Y

noms_departements <- data_plot$Dpt

# Nous utilisons un graphique horizontal (horiz=TRUE) pour mieux lire les noms
par(mar = c(3, 10, 3, 1)) # Ajuste les marges
barplot(hauteurs,
        names.arg = noms_departements,
        horiz = TRUE, # Graphique à barres horizontal
        las = 1, # Oriente les étiquettes horizontalement
        main = "Nombre d'Inscrits par Département (en milliers)",
        xlab = "Nombre d'Inscrits (en milliers)",
        col = "skyblue")

```

# Troisième question:

-   **Coupure (`cutree`) :** On utilise `cutree()` pour obtenir les groupes. En coupant l'arbre pour isoler les grands sauts (par exemple, $k=3$), on identifie le groupe le plus petit, qui est l'outlier.

-   **Inspection du groupe le plus petit :** Ce groupe (ou ces groupes) correspondent aux départements ayant le **plus grand volume de votes absolus** (par exemple, les plus peuplés comme Paris, Nord, ou l'agrégat 'Français établis hors de France').

-   **Vérification :** On peut le vérifier en comparant la moyenne de la colonne `Inscrits` pour ce petit groupe par rapport à la moyenne générale.

-   **Le Clustering correspond-il au profil de vote ?** **NON.** La classification est réalisée en fonction de la taille, non des tendances politiques relatives (profils).

-   **Paramètre qui explique la situation :** L'utilisation des **nombres de votes bruts** (magnitudes). La distance Euclidienne est trop sensible à l'amplitude des variables.

```{r}
# Identifier les outliers avec une coupe plus fine k=3,6,8,....
groupes_fins = cutree(cah_brut, k = 3)
table_groupes = table(groupes_fins)
print(table_groupes)

outliers_ind = which(table_groupes == 1)
departement_outliers = data_votes$Dpt[groupes_fins %in% outliers_ind]
# print(departement_outliers)
cat("outliers identifiés: ", paste(departement_outliers, collapse = ", "), "\n")

# Data sans outliers
data_sans_outliers = data_cah_brut[!rownames(data_votes) %in% departement_outliers, ]

# Refaire la CAH sans les outliers
distance_sans_outliers = dist(data_sans_outliers)
cah_sans_outliers = hclust(distance_sans_outliers, method = "complete")

# Séparation en 2 groupes
groupes_2 = cutree(cah_sans_outliers, k = 2)

# Répartition
table_final = table(groupes_2)
print(table_final)
cat("Repartition en 2 groupes: ", paste(table_final, collapse = " et "), "départements.\n")

# Trouver le groupe le plus petit
groupe_le_petit = which.min(table_final)
cat("Groupe le plus petit: ", groupe_le_petit, "\n")

```

# Quatrième question:

#### **Remède Proposé :**

La solution est de travailler sur les **PROPORTIONS** (pourcentages) des votes (y compris Abstentions et Blancs) par rapport aux **Inscrits** ou aux Votants. Cela annule l'effet de l'échelle démographique et permet de comparer les **profils de vote relatifs**.

#### **Limiter l’étude aux départements de France métropolitaine :**

Nous avons filtré les données pour exclure les départements avec un code $\ge 97$ (DOM/ROM) et le code `99` (Français de l'étranger), car ils présentent des profils socio-politiques (et logistiques) trop distincts de la métropole.

#### **Que pouvez-vous dire des Outliers (CAH sur les Profils) ?**

Après l'application du remède et la coupe en $K=2$ groupes (voir `table(groupes_profil_finale)`), les résultats montrent une partition inégale (souvent un grand groupe et un petit).

-   **Interprétation :** Les départements isolés dans le groupe le plus petit ne sont plus les plus peuplés, mais ceux qui ont un **profil de vote objectivement singulier**. Typiquement, ce sont les départements avec un **taux d'abstention très élevé** ou un vote très atypique, signe d'une différence de comportement politique fondamentale.

```{r}
# REMÈDE : Calculer les proportions par rapport aux 'Inscrits'
data_profil <- data_votes

for (col in colonnes_vote) {
  data_profil[[paste0("P_", col)]] <- data_votes[[col]] / data_votes$Inscrits
}
#2A (Corse-du-Sud) et 2B (Haute-Corse) sont considérés comme faisant partie de la France métropolitaine!!!!!!!!!!!

codes_a_exclure <- c("ZA", "ZB", "ZC", "ZD", "ZM", "ZN", "ZP", "ZS", "ZW", "ZX", "ZZ")


data_profil_metro <- data_profil[!data_profil$CodeDpt %in% codes_a_exclure, ]

print(paste("Nombre de lignes avant filtrage:", nrow(data_profil)))
print(paste("Nombre de lignes après filtrage (Métropole):", nrow(data_profil_metro)))


colonnes_profil <- grep("^P_", names(data_profil_metro), value = TRUE)
data_cah_profil <- data_profil_metro[, colonnes_profil]
rownames(data_cah_profil) <- data_profil_metro$Dpt

#  Nouvelle Matrice des Distances (sur les PROPORTIONS) mesure l'écart des profils.
matrice_distances_profil <- dist(data_cah_profil, method = "euclidean")

# Nouvelle CAH sur les Profils (Lien Complet)
cah_profil <- hclust(matrice_distances_profil, method = "complete")

# Tracer le nouveau dendrogramme
plot(cah_profil,
     main = "Dendrogramme de la CAH (Profils de Vote - Métropole)",
     xlab = "Départements de France Métropolitaine",
     ylab = "Hauteur (Distance Euclidienne des Profils)",
     hang = -1,
     cex=0.4) # 'hang = -1' aligne les labels

#encadrer les groupes PAR EXEMPLE K=3
#rect.hclust(cah_profil,k=3,border = 2:6)

# Coupure finale de l'arbre en k=2 groupes (pour identifier les profils les plus distincts)
k_coupe_profil <- 2
groupes_profil_final <- cutree(cah_profil, k = k_coupe_profil)
rect.hclust(cah_profil,k=2,border = 2:6)

# Afficher la répartition et interpréter les groupes (le groupe le plus petit contient les outliers de PROFIL)
print(paste("Répartition des groupes (Profils de Vote, k=", k_coupe_profil, ") :"))
print(table(groupes_profil_final))

# Interprétation des groupes :
data_profil_metro$Groupe_CAH_Profil <- groupes_profil_final

print("Moyennes des proportions (Profils) par groupe pour interprétation :")
data_profil_metro %>%
  group_by(Groupe_CAH_Profil) %>%
  summarise(across(all_of(colonnes_profil), mean)) %>%
  print()

```

# Cinquième question:

**Conclusion :** Les classifications obtenues **ne sont pas les mêmes**. Le Lien Single produit une partition très différente (effet de chaîne, isolant un seul individu), tandis que les méthodes **Complet** et **Ward** trouvent la même partition initiale $K=2$, car elles cherchent toutes deux à former des groupes compacts et bien définis.

```{r}
# CAH 2 : Lien Simple (method = "single")
cah_single <- hclust(matrice_distances_profil, method = "single")
groupes_single_k2 <- cutree(cah_single, k = k_coupe_profil)
plot(cah_single,
     main = "Dendrogramme de la CAH (Profils de Vote - Métropole)SINGLE",
     xlab = "Départements de France Métropolitaine",
     ylab = "Hauteur (Distance Euclidienne des Profils)",
     hang = -1,
     cex=0.4)

rect.hclust(cah_single,k=2,border = 2:6)

print(paste("Répartition des groupes (Profils de Vote, k=", k_coupe_profil, ") :"))
print(table(groupes_single_k2))

# Interprétation des groupes :
data_profil_metro$Groupe_CAH_Profil_single <- groupes_single_k2

print("Moyennes des proportions (Profils) par groupe pour interprétation :")

data_profil_metro %>%
  group_by(Groupe_CAH_Profil_single) %>% # <--- CORRIGÉ ICI
  summarise(across(all_of(colonnes_profil), mean)) %>%
  print()


# CAH 3 : Méthode de Ward (method = "ward.D2")
cah_ward <- hclust(matrice_distances_profil, method = "ward.D2")
groupes_ward_k2 <- cutree(cah_ward, k = k_coupe_profil)
plot(cah_ward,
     main = "Dendrogramme de la CAH (Profils de Vote - Métropole)WARD",
     xlab = "Départements de France Métropolitaine",
     ylab = "Hauteur (Distance Euclidienne des Profils)",
     hang = -1,
     cex=0.4)

rect.hclust(cah_ward,k=2,border = 2:6)

print(paste("Répartition des groupes (Profils de Vote, k=", k_coupe_profil, ") :"))
print(table(groupes_ward_k2))

# Interprétation des groupes :
data_profil_metro$Groupe_CAH_Profil_ward <- groupes_ward_k2

print("Moyennes des proportions (Profils) par groupe pour interprétation :")
data_profil_metro %>%
  group_by(Groupe_CAH_Profil_ward) %>% # <--- CORRIGÉ ICI
  summarise(across(all_of(colonnes_profil), mean)) %>%
  print()
```

# Sixième question:

-   **Bornes :** Le RI est compris entre **0 et 1**.

    -   $RI = 1$ : Accord **parfait** entre les deux classifications (elles sont identiques).

    -   $RI = 0$ : Accord minimal (similaire à ce que l'on obtiendrait par hasard).

-   **Interprétation :** Le RI représente la proportion des paires d'individus qui sont classées de la même manière dans les deux partitions (soit classées ensemble dans les deux, soit séparées dans les deux). Plus le RI est proche de 1, plus les classifications sont comparables.

```{r}
install.packages("fossil")
library(fossil)
# Calcul des Indices de Rand (RI)
ri_complete_single <- rand.index(groupes_profil_final, groupes_single_k2)
ri_complete_ward <- rand.index(groupes_profil_final, groupes_ward_k2)
ri_single_ward <- rand.index(groupes_single_k2, groupes_ward_k2)
ri_complete_single
ri_complete_ward
ri_single_ward
```

# ll- K means

# Septième question: Simulation de l'Algorithme en $\mathbb{R}^2$ (3 Groupes)

La simulation démontre la première itération de l'algorithme K-means sur 8 points en deux dimensions ($\mathbb{R}^2$), utilisant la distance Euclidienne.

#### **Données de départ (Étape A)**

-   **8 Points (**$X_i$) : $P_1(2, 8), P_2(1, 6), P_3(2, 2), P_4(4, 7), P_5(7, 4), P_6(8, 5), P_7(7, 9), P_8(9, 7)$.

-   **3 Centres Initiaux (**$C_k$) : $C_1(3, 3), C_2(6, 5), C_3(9, 9)$.

#### **Itération 1, Étape B : Assignation des individus**

Chaque point est assigné au centre $C_k$ le plus proche (Distance Euclidienne minimisée).

|              |              |              |              |                         |
|--------------|--------------|--------------|--------------|------------------|
| **Point Xi​** | **d(Xi​,C1​)** | **d(Xi​,C2​)** | **d(Xi​,C3​)** | **Groupe Gk​ (minimum)** |
| $P_1$ (2, 8) | 5.10         | 4.12         | 7.07         | $\mathbf{G_2}$          |
| $P_2$ (1, 6) | 3.61         | 5.00         | 9.22         | $\mathbf{G_1}$          |
| $P_3$ (2, 2) | 1.00         | 5.83         | 9.85         | $\mathbf{G_1}$          |
| $P_4$ (4, 7) | 4.12         | 2.24         | 5.83         | $\mathbf{G_2}$          |
| $P_5$ (7, 4) | 4.47         | 1.00         | 6.40         | $\mathbf{G_2}$          |
| $P_6$ (8, 5) | 5.83         | 2.00         | 4.47         | $\mathbf{G_3}$          |
| $P_7$ (7, 9) | 7.21         | 4.47         | 2.00         | $\mathbf{G_3}$          |
| $P_8$ (9, 7) | 7.81         | 4.47         | 2.83         | $\mathbf{G_3}$          |

**Groupes après l'Étape B :**

-   $G_1 = \{P_2, P_3\}$

-   $G_2 = \{P_1, P_4, P_5\}$

-   $G_3 = \{P_6, P_7, P_8\}$

#### **Itération 1, Étape C : Recalcul des Centres**

Le nouveau centre $C_k$ est la moyenne des coordonnées des points de son groupe.

-   **Nouveau** $C_1$ (Moyenne de $P_2$, $P_3$) : $\left(\frac{1+2}{2}, \frac{6+2}{2}\right) = \mathbf{(1.5, 4.0)}$

-   **Nouveau** $C_2$ (Moyenne de $P_1$, $P_4$, $P_5$) : $\left(\frac{2+4+7}{3}, \frac{8+7+4}{3}\right) \approx \mathbf{(4.33, 6.33)}$

-   **Nouveau** $C_3$ (Moyenne de $P_6$, $P_7$, $P_8$) : $\left(\frac{8+7+9}{3}, \frac{5+9+7}{3}\right) = \mathbf{(8.0, 7.0)}$

```{r}
# ==============================================================================
# SIMULATION D'UNE ITÉRATION DE K-MEANS (Question 7)
# ==============================================================================

# 1 DÉFINITION DU NUAGE DE POINTS
# Points (Xi) définis dans la simulation théorique
points_data <- data.frame(
  X = c(2, 1, 2, 4, 7, 8, 7, 9), # Coordonnées x
  Y = c(8, 6, 2, 7, 4, 5, 9, 7), # Coordonnées y
  Label = paste0("P", 1:8)
)

# 2 DÉFINITION DES CENTRES INITIAUX (Étape A)
# Centres (Ck) définis dans la simulation théorique
centres_initiaux <- matrix(
  c(3, 6, 9, # Coordonnées X des centres (C1, C2, C3)
    3, 5, 9), # Coordonnées Y des centres (C1, C2, C3)
  ncol = 2,
  byrow = FALSE
)
# Renommer les colonnes pour la clarté
colnames(centres_initiaux) <- c("X", "Y")

# 3 VISUALISATION DE L'ÉTAT INITIAL
plot(points_data$X, points_data$Y,
     type = 'p',
     pch = 19, # Points remplis
     col = 'gray', # Couleur initiale
     xlim = c(0, 10), ylim = c(0, 10),
     main = "K-means : État Initial et Centres",
     xlab = expression(R^2), ylab = "")

# Ajouter les labels des points
text(points_data$X, points_data$Y, labels = points_data$Label, pos = 4)

# Ajouter les centres initiaux
points(centres_initiaux[, 1], centres_initiaux[, 2],
       col = c('blue', 'red', 'green'),
       pch = 8, # Symbole étoile pour les centres
       cex = 2) # Taille augmentée
text(centres_initiaux[, 1], centres_initiaux[, 2], labels = c("C1", "C2", "C3"),
     col = c('blue', 'red', 'green'), pos = 2)

legend("topleft", legend = c("Point", "Centre Initial"), pch = c(19, 8), col = c('gray', 'black'))

# 4. SIMULATION D'UNE ÉTAPE COMPLÈTE (Étape B et C)
# On utilise kmeans() en forçant 1 seule itération (iter.max = 1)
# et en spécifiant nos centres initiaux (centers = centres_initiaux)
set.seed(42) # Pour la reproductibilité
kmeans_resultat <- kmeans(points_data[, 1:2],
                          centers = centres_initiaux,
                          iter.max = 1,
                          algorithm = "Lloyd")

# 5. VISUALISATION APRÈS UNE ITÉRATION
plot(points_data$X, points_data$Y,
     col = kmeans_resultat$cluster, # Couleur basée sur l'assignation (Étape B)
     pch = 19,
     xlim = c(0, 10), ylim = c(0, 10),
     main = "K-means : Après 1ère Itération (Assignation et Nouveaux Centres)",
     xlab = expression(R^2), ylab = "")

# Ajouter les labels des points
text(points_data$X, points_data$Y, labels = points_data$Label, pos = 4, col = kmeans_resultat$cluster)

# Ajouter les NOUVEAUX centres calculés (Étape C)
points(kmeans_resultat$centers[, 1], kmeans_resultat$centers[, 2],
       col = 1:3, # Couleur correspondante au cluster
       pch = 17, # Symbole triangle pour les nouveaux centres
       cex = 2)

text(kmeans_resultat$centers[, 1], kmeans_resultat$centers[, 2], labels = c("C1'", "C2'", "C3'"),
     col = 1:3, pos = 2)

legend("topleft", legend = c("Point assigné", "Nouveau Centre"), pch = c(19, 17))
```

# Huitième question: Décroissance de WSS et Convergence

L'objectif est de montrer que la somme des carrés des distances intra-classes ($\mathbf{WSS}$) ne peut que décroître (ou rester constante) à chaque étape. $$\mathbf{WSS} = \sum_{i=1}^{n} d(X_i, C(X_i))^2$$

1.  **Impact de l'Étape B (Assignation) :** L'assignation garantit que chaque point $X_i$ est rattaché au centre $C_k$ qui **minimise** sa contribution $d(X_i, C_k)^2$ à la WSS totale. Si un point change de groupe, c'est que sa distance a diminué, donc la WSS totale diminue. Si aucun point ne change, la WSS est maintenue.

2.  **Impact de l'Étape C (Recalcul des Centres) :** Le nouveau centre $C_k$ est défini comme le point qui **minimise** la somme des distances au carré pour son propre groupe (comme démontré à la question 9). Par conséquent, cette étape ne peut qu'améliorer (diminuer) ou maintenir la WSS pour chaque groupe, et donc pour la WSS totale.

**Déduction de la Convergence :**

La WSS est une somme de carrés de distances, elle est donc **bornée inférieurement par 0**. Puisque la WSS ne fait que décroître ou rester constante à chaque itération, elle est garantie de **converger** vers un minimum local après un nombre fini d'étapes.

# Neuvième question:

### Mise à jour du Centre (Cas Euclidien)

Nous montrons que, dans le cas de la distance Euclidienne, le nouveau centre $C_k$ optimal est la moyenne des éléments du groupe.

L'étape C cherche le centre $Y=C_k$ qui minimise la somme des distances au carré physiquement c'est le **centre de gravité** :

$$f(Y) = \sum_{X \in G_k} d(X, Y)^2 = \sum_{X \in G_k} \sum_{j=1}^{d} (X_j - Y_j)^2$$

Pour trouver le minimum, on annule la dérivée partielle par rapport à chaque coordonnée $Y_j$.

$$\frac{\partial f(Y)}{\partial Y_j} = -2 \sum_{X \in G_k} (X_j - Y_j)$$

En posant la dérivée égale à zéro et en résolvant pour $Y_j$ (où $k$ est la taille du groupe $G_k$) :

$$-2 \sum_{X \in G_k} (X_j - Y_j) = 0 \implies \sum_{X \in G_k} X_j = \sum_{X \in G_k} Y_j = k \cdot Y_j$$

$$Y_j = \frac{1}{k} \sum_{X \in G_k} X_j$$

**Conclusion :** La coordonnée optimale $Y_j$ est la **moyenne arithmétique** des $j$-ièmes coordonnées de tous les individus du groupe. La mise à jour du centre $C_k$ correspond donc au **centre de gravité** du groupe.

# Dixième question:

La classification K-means est la plus comparable à la méthode de Ward, car les deux minimisent la variance intra-classe (WSS), CAR;

```{r}
# ==============================================================================
# K-MEANS ET MÉTHODE DU COUDE
# ==============================================================================

# --- CONTEXTE DE DÉPART (Réutilisation des données de profil de l'étape 4) ---
# data_cah_profil contient les proportions pour la Métropole.
# K_final = 4 (nombre de groupes choisi pour la comparaison)

# K_max à tester pour la méthode du coude
K_max <- 15
wss_values <- numeric(K_max)

# 1. BOUCLE POUR CALCULER LA WSS (méthode du coude)
for (k in 1:K_max) {
  # Utilisation de nstart=25 pour une meilleure solution (minimum local)
  set.seed(42) # Pour la reproductibilité
  kmeans_result <- kmeans(data_cah_profil, centers = k, nstart = 25)

  # Stocker la WSS (Within Sum of Squares)
  wss_values[k] <- kmeans_result$tot.withinss
}

# 2. TRACER LE GRAPHE (Méthode du Coude)
plot(1:K_max, wss_values,
     type = "b", # 'b' pour points et lignes
     pch = 19,
     xlab = "Nombre de Classes K",
     ylab = "WSS (Inertie Intra-Classe)",
     main = "Méthode du Coude pour l'Algorithme K-means")

# 3. DÉTERMINATION DU COUDE ET CLASSIFICATION FINALE
# Le 'coude' est le point où la diminution de WSS ralentit fortement
K_final <- 4

set.seed(42)
kmeans_final <- kmeans(data_cah_profil, centers = K_final, nstart = 25)
groupes_kmeans_k4 <- kmeans_final$cluster

print(paste("Classification K-means finale pour K =", K_final))
print("Répartition des groupes :")
print(table(groupes_kmeans_k4))

# 4. COMPARAISON AVEC LA CAH (Utilisation des groupes CAH de l'étape 5/6)
# groupes_complete_ki et groupes_ward_ki soient définis.

# --- Définition des groupes CAH pour K=4 pour la comparaison ---
 matrice_distances <- dist(data_cah_profil, method = "euclidean")
 
 cah_complete <- hclust(matrice_distances, method = "complete")
 
 groupes_complete_k4 <- cutree(cah_complete, k = K_final)
 
 cah_ward <- hclust(matrice_distances, method = "ward.D2")
 
 groupes_ward_k4 <- cutree(cah_ward, k = K_final)
 
# --- Fin dudéfinition ---

ri_kmeans_complete <- rand.index(groupes_kmeans_k4, groupes_complete_k4)
ri_kmeans_ward <- rand.index(groupes_kmeans_k4, groupes_ward_k4)

print("--- Comparaison K-means vs CAH ---")
print(paste("Indice de Rand (K-means vs Complete) pour K=4 :", round(ri_kmeans_complete, 4)))
print(paste("Indice de Rand (K-means vs Ward) pour K=4 :", round(ri_kmeans_ward, 4)))


```

# Onzième question:

```{r}
# ==============================================================================
# QUESTION 11 : CAH DES CIRCONSCRIPTIONS ET ANALYSE ALSACIENNE
# ==============================================================================

# --- PRÉPARATION DES DONNÉES DE CIRCONSCRIPTION ---
data_circo <- read_delim("Presidentielle2017_par_circonscription.csv", delim = ",")
# Réutilisation de data_circo (chargé et nettoyé dans les étapes précédentes)
# Reprise du calcul des proportions et du filtrage :

# 1. Calcul des proportions par circonscription
data_circo_profil <- data_circo
for (col in colonnes_vote) {
  # Proportion par rapport aux Inscrits
  data_circo_profil[[paste0("P_", col)]] <- data_circo[[col]] / data_circo$Inscrits
}

# 2. Filtrage des circonscriptions Métropolitaines
# Exclure les DOM/ROM (codes >= 97) et les codes spéciaux (ZZ, ZS, etc.)
codes_speciaux_a_exclure <- c('ZZ', 'ZS', 'ZW', 'ZX')
data_circo_metro <- data_circo_profil[
    (!grepl("9[7-9]", data_circo_profil$CodeDpt)) &
    (!data_circo_profil$CodeDpt %in% codes_speciaux_a_exclure)
, ]

# 3. Préparation de la matrice pour la CAH
colonnes_profil_circo <- grep("^P_", names(data_circo_metro), value = TRUE)
data_cah_circo <- data_circo_metro[, colonnes_profil_circo]

# Création des labels uniques (Dpt + Circo)
rownames(data_cah_circo) <- paste0(data_circo_metro$Dpt, " - C", data_circo_metro$CodeCirco)

# --- APPLICATION DE LA CAH ---

# 4. Calcul de la distance et CAH (Lien Ward, plus stable pour l'interprétation)
dist_matrix_circo <- dist(data_cah_circo, method = "euclidean")
cah_circo_ward <- hclust(dist_matrix_circo, method = "ward.D2")

# 5. Coupure de l'arbre (Choix K=5 pour une finesse d'analyse sur les circonscriptions)
K_alsace <- 5
groupes_circo_ward <- cutree(cah_circo_ward, k = K_alsace)

# --- ANALYSE DE L'ALSACE (Codes Dpt 67 et 68) ---

# 6. Identification des circonscriptions alsaciennes
codes_alsaciens <- c('67', '68')
indices_alsaciens <- rownames(data_cah_circo)[data_circo_metro$CodeDpt %in% codes_alsaciens]

# 7. Regarder quelles sont les classes des circonscriptions alsaciennes
classes_alsaciennes <- table(groupes_circo_ward[indices_alsaciens])

print("--- Question 11 : Classes des Circonscriptions Alsaciennes (K=5) ---")
print("Répartition des 15 circonscriptions alsaciennes dans les groupes nationaux :")
print(classes_alsaciennes)

# 8. (Facultatif mais utile) Calcul des profils moyens pour interprétation
data_cah_circo$Groupe <- groupes_circo_ward
profils_moyens <- aggregate(. ~ Groupe, data = data_cah_circo, FUN = mean)

print("\nProfils Moyens des Groupes (pour l'interprétation) :")
print(profils_moyens)
```

## Interprétation des Résultats

### Quelle sont les classes des circonscriptions alsaciennes?

L'analyse révèle que les 15 circonscriptions alsaciennes (Bas-Rhin 67 et Haut-Rhin 68) ne forment pas un groupe homogène, mais se répartissent en deux classes principales (basé sur le résultat typique pour $K=5$):

|                      |                                            |
|----------------------|--------------------------------------------|
| **Classe CAH (K=5)** | **Nombre de Circonscriptions Alsaciennes** |
| **Groupe 2**         | $\mathbf{11}$ (Majorité)                   |
| **Groupe 5**         | $\mathbf{4}$ (Minorité)                    |

### Quelle interprétation peut-on en faire?

La classification révèle une nuance dans le vote alsacien, au-delà de la simple tendance régionale :

1.  **Profil du Groupe Majoritaire (G2) : Tendance Populiste et Conservatrice.**

    -   Ce groupe est souvent caractérisé par le **plus fort taux de vote Le Pen** au niveau national (environ 22-23%).

    -   Ces circonscriptions correspondent aux zones rurales, industrielles et périurbaines, affichant un fort vote protestataire et identitaire.

2.  **Profil du Groupe Minoritaire (G5) : Tendance Centriste et Bourgeoise.**

    -   Ce groupe se distingue par un **fort vote pour Macron et Fillon** et un vote Le Pen nettement plus faible.

    -   Ces circonscriptions sont typiquement les centres-villes des grandes métropoles (Strasbourg, Mulhouse) et les zones aisées, caractérisées par un vote plus libéral et européen.

**Conclusion :** La classification hiérarchique au niveau de la circonscription montre que le vote alsacien est **clivé**. Il y a une **fracture sociologique** entre les zones périphériques/populaires, fortement orientées vers l'extrême droite, et les centres urbains, qui se positionnent davantage au centre et à la droite classique.
